from __future__ import annotations
import os
from pathlib import Path
import google.generativeai as genai
import logging
from google.api_core import exceptions as gax_exceptions

logger = logging.getLogger(__name__)


# 1) ì•ˆì „í•œ ê¸°ë³¸ê°’ê³¼ í´ë°± ë§µ
PREFERRED_MODELS = [
    "gemini-2.5-flash-lite",  # ê°€ì¥ ì €ë ´/ê³ ì† (ê°€ìš© ì‹œ)
    "gemini-2.0-flash",       # ë²”ìš© ê³ ì†
    "gemini-2.0-pro",         # ì •êµí•¨/ê¸´ë§¥ë½
]

# ê¸°ì¡´: "gemini-1.5-flash-002" â†’ ì‚­ì œ
def _get_first_available_model():
    # ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒë¡œ ì‹¤ì œ ê°€ìš© ëª¨ë¸ í™•ì¸
    try:
        available = {m.name for m in genai.list_models()}
        for m in PREFERRED_MODELS:
            if m in available:
                return m
    except Exception:
        pass
    # ì¡°íšŒ ì‹¤íŒ¨ ì‹œì—ë„ ë¬´ë‚œí•œ ê¸°ë³¸ê°’
    return "gemini-2.0-flash"

# ===== Gemini í´ë¼ì´ì–¸íŠ¸ =====
class GeminiClient:
    def __init__(self, prompt_file: str = "resources/daily_briefing_prompt.md"):
        self.prompt_file = Path(prompt_file)

        # API í‚¤: í™˜ê²½ì„¤ì •ì—ì„œ ì½ìŒ
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            # ğŸ”¹ API í‚¤ê°€ ì—†ìœ¼ë©´ RuntimeErrorë¥¼ ë°œìƒì‹œì¼œ í˜¸ì¶œìì—ê²Œ ì•Œë¦¼
            raise RuntimeError("í™˜ê²½ë³€ìˆ˜ GEMINI_API_KEY ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        genai.configure(api_key=api_key)
        self.model_name = _get_first_available_model()
        self.model = genai.GenerativeModel(self.model_name)


    def _load_prompt(self) -> str:
        if not self.prompt_file.exists():
            # ğŸ”¹ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ FileNotFoundErrorë¥¼ ë°œìƒ
            raise FileNotFoundError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì—†ìŒ: {self.prompt_file}")
        return self.prompt_file.read_text(encoding="utf-8").strip()

    def run_briefing(self, extra_context: str | None = None) -> str:
        """
        - í”„ë¡¬í”„íŠ¸ íŒŒì¼ì—ì„œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        - í•„ìš”ì‹œ ì¶”ê°€ context ë¶™ì—¬ Gemini í˜¸ì¶œ
        """
        try:
            base_prompt = self._load_prompt()
            if extra_context:
                full_prompt = f"{base_prompt}\n\nì¶”ê°€ ì •ë³´:\n{extra_context}"
            else:
                full_prompt = base_prompt

            response = self.model.generate_content(full_prompt)
            return response.text.strip() if hasattr(response, "text") else str(response)
        except Exception as e:
            # ğŸ”¹ API í˜¸ì¶œ ì¤‘ ë°œìƒí•œ ì˜ˆì™¸ë¥¼ ë¡œê·¸í•˜ê³  ë‹¤ì‹œ ë°œìƒì‹œí‚´
            if "gemini-1.5" in str(e) or "Publisher Model" in str(e):
                self.model_name = _get_first_available_model()
                self.model = genai.GenerativeModel(self.model_name)
                return self.model.generate_content(full_prompt).text
            logger.exception("Gemini content generation failed.")

            raise e